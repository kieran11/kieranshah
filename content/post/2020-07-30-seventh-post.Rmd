---
title: Prediction with Python
author: ''
date: '2020-08-06'
slug: sixth-post
categories:
  - R
tags: []
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
```

## Using Python and Reticulate:

Reticulate is a `R` package that allows us to implement `python` within an `R markdown` file. This post shows how to do some basic predictive analysis using the same NBA dataset we used in prior posts.  


```{r pckgs}

library(reticulate)
library(dplyr)
library(gt)
library(ggplot2)

```


We first need to read in the data. Below is some basic code to bring in a csv file. 

```{python, echo=TRUE}

import pandas as pd
import numpy as np

AnalyticalDS = pd.read_csv('NBAData/AnalysisDS.csv')

```

The plot below shows the distribution of minutes played for all players who were active. The code below is `R`. It shows the distribution of the minutes played variable `mp`. We use minutes played instead of seasons because it is a better representation of longevity than seasons. 

However, the `R` plot shows both: 

```{r showR}

R_plt = py$AnalyticalDS %>% 
  filter(LastSeason != "2019-20" ) %>% 
  tidyr::gather(Var, Val, mp, NumberOfSeasons) %>% 
  filter(!is.na(Val)) %>% 
  ggplot(., aes(x = Val)) +
  geom_density() +
  theme_classic() +
  facet_wrap(~Var, scales = "free")
R_plt

```


The next section code shows the same two plots but in `python`. As far as I can tell, there is not a perfect substitution for `facet_wrap` with `scale = 'free'`. You can import a `python` module [ggplot](http://ggplot.yhathq.com/#:~:text=ggplot%20is%20a%20plotting%20system,plots%20quickly%20with%20minimal%20code.), but that seems to defeat the purpose. The major advantage of `scales = 'free'` is that you show the distrbution for two very different variables. 

Instead, we use the `seaborn` module to show the same plots: 

```{python mltData }

Dimension = AnalyticalDS.shape


```

The first plot shows the `distplot` function for minutes played. The second plot is the same, but for `NumberOfSeasons`. 

```{python DenPymp, echo = TRUE}

import seaborn as sns

sns.distplot(AnalyticalDS['mp'], hist = False)

```

```{python DenPyNS}

import seaborn as sns

sns.distplot(AnalyticalDS['NumberOfSeasons'], hist = False)

```


The next step is to finalize the dataset, the training dataset, and then the testing dataset. We first need to select the variables of interest, and then divide the data up. The below code removes any active players and players who had zero minutes. It also selects the variables we will need for our analysis.  

```{python flt, echo = TRUE}

AboveMP_zero = AnalyticalDS['mp'] > 0
NotCurrent = AnalyticalDS['LastSeason'] != "2019-20"
AnalyticalDS_2 = AnalyticalDS[AboveMP_zero]
AnalyticalDS_2_a = AnalyticalDS_2[NotCurrent]

AnalyticDS_3 = AnalyticalDS_2_a[['link' ,'mp', 'age', 'FirstSeasonMP', 'fg', 'fga', 'ftpercent', 'FirstSeasonMP', 'PickNumber', 'fga', 'x3p', 'x3pa', 'x3ppercent', 'x2p' , 
'x2pa', 'x2ppercent', 'fgpercent', 'ft', 'fta', 'efgpercent', 'orb', 'drb', 'trb', 'ast', 'stl', 'blk', 'tov', 'pts','wprev', 'w_lpercentprev',  'wcur', 'w_lpercentcur']]

```


```{python CheckMissing}

AnalyticDS_4 = AnalyticDS_3.dropna()

CheckSize = AnalyticDS_4.shape


```

This next section make the float variable `PickNumber` a categorical variable, and then a dummy variable with `pandas` module, using the function `get_dummies`. We then scale our continuous variables with a mean of zero, and a standard deviation of one.  

Finally, we divide our data into a training and test datasets. 


```{python slct , eval = TRUE}

from sklearn import preprocessing


Features = AnalyticDS_4.drop(['mp', 'PickNumber', 'link'], axis=1)
#MainVar = np.array( AnalyticDS_4[['mp']] )
MainVar =  AnalyticDS_4[['mp', 'link']] 
PickNumber = AnalyticDS_4[['PickNumber', 'link']] 

conditions = [
    (PickNumber['PickNumber'] <= 5),
    (PickNumber['PickNumber'] > 5) & (PickNumber['PickNumber'] <= 16),
    (PickNumber['PickNumber'] > 16) & (PickNumber['PickNumber'] <= 30),
    (PickNumber['PickNumber'] > 30)
    ]

values = [ 'round_1_early', 'round_1_mid','round_1_late', 'round_2']

# create a new column and use np.select to assign values to it using our lists as arguments
PickNumber['DraftCat'] = np.select(conditions, values)

PickNumberDummy = pd.get_dummies(PickNumber, columns=['DraftCat'])

Analytic_scaled = preprocessing.scale(Features)
Analytic_scaled_df_a = pd.DataFrame(data=Analytic_scaled) 


Analytic_scaled_df_a.reset_index(drop=True, inplace=True)
MainVar.reset_index(drop = True, inplace = True)

Analytical_scaled_b = pd.concat([MainVar, Analytic_scaled_df_a], axis= 1, ignore_index = True)
Analytical_scaled_c = Analytical_scaled_b.rename(columns={1: "link", 0: "mp"})

Analytic_scaled_df = pd.merge(PickNumberDummy,Analytical_scaled_c,on='link')

# Analytic_scaled_df = pd.concat([Analytic_scaled_df_a, PickNumberDummy_lnk], axis = 1, ignore_index=True)



```

The first algorithm we use is a ramdom forest. There is a very good description of how the algorithm actually works is [here](https://medium.com/datadriveninvestor/random-forest-regression-9871bc9a25eb). There are many ways to evaluate a random forest algorithm; however, we will not do that here. It is possible to visualize a tree, and look at the Variable Importance. For an extensive discussion, see [here](https://towardsdatascience.com/random-forest-in-python-24d0893d51c0).

The basic idea of a random forest is that it aggregates decision trees. Bagging uses a decision tree on a different dataset with sample with replacement technique.  

```{python , results = 'hide'}

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor

AnalyticsSplit = Analytic_scaled_df.drop(['mp' , 'link'], axis=1)
Depend = Analytic_scaled_df[['mp']]

Depend2 = np.array( Depend[['mp']] )

X_trainDF, X_testDF, Y_trainDF, Y_testDF = train_test_split(AnalyticsSplit,
Depend2, test_size=0.3, random_state = 0)
# 
X_trainDF_2 = X_trainDF.drop('PickNumber', 1)
X_test_DF_2 = X_testDF.drop('PickNumber', 1)

regressor = RandomForestRegressor(n_estimators = 10, random_state = 32)
Results = regressor.fit(X_trainDF_2, Y_trainDF)
#
predictions = regressor.predict(X_test_DF_2)

```

## Lasso

The next technique uses a lasso regression. Lasso regressions are [unstable](https://stats.stackexchange.com/questions/365938/what-causes-lasso-to-be-unstable-for-feature-selection), which means that they do not consistently select the same features. Random forests are far more stable, which is a big advantage. To get out around the unstable nature of Lasso, we first try to bootstrap the lasso regression. We simply use 100 bootstraps for this example. Lasso is a simple linear regression, but with an extra parameter for shrinkage. Shrinkage attempts to minimize the parameters towards zero. 

```{python Baseline, results = 'hide'}

# 
# Baseline_a = pd.DataFrame(X_trainDF[['round_1_early', 'round_1_mid','round_1_late', 'round_2']])
# 

Y_trainDF_DF = pd.DataFrame(Y_trainDF)

Y_trainDF_DF.reset_index(drop=True, inplace=True)
X_trainDF.reset_index(drop = True, inplace = True)

Baseline_a = pd.concat([X_trainDF[['PickNumber']], Y_trainDF_DF],  axis= 1, ignore_index = True)

Baseline_b = Baseline_a.rename(columns={0: "PickNumber"})


conditions2 = [
    (Baseline_b['PickNumber'] <= 5),
    (Baseline_b['PickNumber'] > 5) & (Baseline_b['PickNumber'] <= 16),
    (Baseline_b['PickNumber'] > 16) & (Baseline_b['PickNumber'] <= 30),
    (Baseline_b['PickNumber'] > 30)
    ]
    
conditions3 = [
    (X_testDF['PickNumber'] <= 5),
    (X_testDF['PickNumber'] > 5) & (X_testDF['PickNumber'] <= 16),
    (X_testDF['PickNumber'] > 16) & (X_testDF['PickNumber'] <= 30),
    (X_testDF['PickNumber'] > 30)
    ]    


Baseline_b['DraftCat'] = np.select(conditions2, values)

Baseline = Baseline_b.groupby(['DraftCat']).mean('mp')


X_testDF['DraftCat'] = np.select(conditions3, values)
Baseline_f = pd.merge(X_testDF['DraftCat'],Baseline,on='DraftCat')


```


```{python lassobt , results = 'hide', cache = FALSE}

from sklearn.linear_model import Lasso
from sklearn.model_selection import GridSearchCV
from sklearn.utils import resample
from sklearn.linear_model import LinearRegression

parameters = {'alpha': [1e-15,1e-10, 1e-8, 1e-4, 1e-3, 1e-2, 1, 5, 10, 20 ]}
n_iterations = 100
# run bootstrap
seed=42
np.random.seed(seed)
stats = list()
for i in range(n_iterations):
  # prepare train and test sets
	X, y = resample(X_trainDF_2, Y_trainDF)
	lasso = Lasso()
	lasso_regressor = GridSearchCV(lasso, parameters,scoring = 'neg_mean_squared_error', cv = 5)
	lasso_regressor.fit( X , y)
	predictions = lasso_regressor.predict(X_test_DF_2)
	stats.append(predictions)

df = pd.DataFrame(stats)
df2 = pd.melt(df)
MnLasso = df2.groupby(['variable']).mean()

	
```	
	
```{python BsLasso, results = 'hide'}

lasso_rg = Lasso()
lasso_reg = GridSearchCV(lasso_rg, parameters,scoring = 'neg_mean_squared_error', cv = 5)
# 
lasso_reg.fit( X_trainDF_2 , Y_trainDF)
predictions_lasso = lasso_reg.predict(X_test_DF_2)

```
	


```{python evalMdls , eval = TRUE, results = 'hide'}

import statistics

RF = pd.DataFrame(predictions)
OneLasso = pd.DataFrame(predictions_lasso)
Actuals = pd.DataFrame(Y_testDF)
Eval = pd.concat([RF, MnLasso, OneLasso, Baseline_f[[1]], Actuals ] , axis=1, ignore_index=True)

Rslts = list()

for i in range(4):
  Diff = statistics.mean( abs( Eval[i] - Eval[4] ) )
  Rslts.append(Diff)


Nms = ['Random_Forest', 'Bootstrapped_Lasso', 'Lasso', 'Baseline', 'Actuals'] 
EvaluationsFinal = pd.DataFrame(list(zip( Nms, Rslts)), 
               columns =['Model Name', 'Mean Absolute Error'])


```

The final comparison is uses a simple grouped mean. We take the mean by the category of draft pick. A high draft pick, medium draft pick, etc... 

The goal is to at least outperform the basic grouped mean. 

The final table shows that the bootstrapped lasso performs the best. The metric is simply the mean absolute error. 


```{r}

py$EvaluationsFinal %>% 
  gt()

```

## Summary

The post is pretty simple in that it takes three methods, and attempts to use some basic supervised learning to best predict minutes played among a group of NBA players who are no longer active. 

We use a random forest and a lasso regresion, and a third method that uses the lasso algorithm, but with a bootstrap. Overall, we find that the bootstrap lasso performs the best, as the above table can be seen above. 


